{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **INSTALLING THE NECESSARY LIBRARIES**","metadata":{}},{"cell_type":"code","source":"pip install evaluate","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:28:16.609353Z","iopub.execute_input":"2024-04-12T22:28:16.609718Z","iopub.status.idle":"2024-04-12T22:28:31.272111Z","shell.execute_reply.started":"2024-04-12T22:28:16.609690Z","shell.execute_reply":"2024-04-12T22:28:31.270761Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.18.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.2.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.22.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nCollecting responses<0.19 (from evaluate)\n  Downloading responses-0.18.0-py3-none-any.whl.metadata (29 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (15.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (0.6)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.4)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading responses-0.18.0-py3-none-any.whl (38 kB)\nInstalling collected packages: responses, evaluate\nSuccessfully installed evaluate-0.4.1 responses-0.18.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip -q install datasets","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:28:31.274238Z","iopub.execute_input":"2024-04-12T22:28:31.274650Z","iopub.status.idle":"2024-04-12T22:28:44.937226Z","shell.execute_reply.started":"2024-04-12T22:28:31.274619Z","shell.execute_reply":"2024-04-12T22:28:44.935879Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Note: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install transformers","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:28:44.938605Z","iopub.execute_input":"2024-04-12T22:28:44.938921Z","iopub.status.idle":"2024-04-12T22:28:58.639552Z","shell.execute_reply.started":"2024-04-12T22:28:44.938890Z","shell.execute_reply":"2024-04-12T22:28:58.638274Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.39.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.22.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.2)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install transformers[torch]","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:28:58.642959Z","iopub.execute_input":"2024-04-12T22:28:58.643301Z","iopub.status.idle":"2024-04-12T22:29:12.226064Z","shell.execute_reply.started":"2024-04-12T22:28:58.643269Z","shell.execute_reply":"2024-04-12T22:29:12.224761Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers[torch] in /opt/conda/lib/python3.10/site-packages (4.39.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.22.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.4.2)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (4.66.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.1.2)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.28.0)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.3)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2024.2.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers[torch]) (3.1.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->transformers[torch]) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->transformers[torch]) (1.3.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install --upgrade transformers","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:29:12.227999Z","iopub.execute_input":"2024-04-12T22:29:12.228348Z","iopub.status.idle":"2024-04-12T22:29:26.045374Z","shell.execute_reply.started":"2024-04-12T22:29:12.228302Z","shell.execute_reply":"2024-04-12T22:29:26.043738Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.39.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.22.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.2)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install accelerate -U","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:29:26.047420Z","iopub.execute_input":"2024-04-12T22:29:26.047817Z","iopub.status.idle":"2024-04-12T22:29:40.966175Z","shell.execute_reply.started":"2024-04-12T22:29:26.047780Z","shell.execute_reply":"2024-04-12T22:29:40.964804Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.28.0)\nCollecting accelerate\n  Downloading accelerate-0.29.2-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.22.2)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.2.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nDownloading accelerate-0.29.2-py3-none-any.whl (297 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.4/297.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hInstalling collected packages: accelerate\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.28.0\n    Uninstalling accelerate-0.28.0:\n      Successfully uninstalled accelerate-0.28.0\nSuccessfully installed accelerate-0.29.2\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install sacrebleu","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:29:40.967781Z","iopub.execute_input":"2024-04-12T22:29:40.968116Z","iopub.status.idle":"2024-04-12T22:29:55.493462Z","shell.execute_reply.started":"2024-04-12T22:29:40.968084Z","shell.execute_reply":"2024-04-12T22:29:55.492197Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Collecting sacrebleu\n  Downloading sacrebleu-2.4.2-py3-none-any.whl.metadata (58 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.0/58.0 kB\u001b[0m \u001b[31m928.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting portalocker (from sacrebleu)\n  Downloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (2023.12.25)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (1.26.4)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (5.2.1)\nDownloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading portalocker-2.8.2-py3-none-any.whl (17 kB)\nInstalling collected packages: portalocker, sacrebleu\nSuccessfully installed portalocker-2.8.2 sacrebleu-2.4.2\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install huggingface-hub","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:29:55.495238Z","iopub.execute_input":"2024-04-12T22:29:55.495684Z","iopub.status.idle":"2024-04-12T22:30:09.411211Z","shell.execute_reply.started":"2024-04-12T22:29:55.495632Z","shell.execute_reply":"2024-04-12T22:30:09.409962Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (0.22.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub) (2024.2.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub) (6.0.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub) (4.66.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub) (2024.2.2)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install wandb","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:30:09.412713Z","iopub.execute_input":"2024-04-12T22:30:09.413048Z","iopub.status.idle":"2024-04-12T22:30:23.023164Z","shell.execute_reply.started":"2024-04-12T22:30:09.413009Z","shell.execute_reply":"2024-04-12T22:30:23.021900Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.16.5)\nRequirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.41)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.44.1)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.1)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (69.0.3)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **CONFIGURING THE WANDB & HUGGINGFACE HUB**","metadata":{}},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\n!notebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-04-12T17:01:29.511818Z","iopub.execute_input":"2024-04-12T17:01:29.512800Z","iopub.status.idle":"2024-04-12T17:01:30.621205Z","shell.execute_reply.started":"2024-04-12T17:01:29.512759Z","shell.execute_reply":"2024-04-12T17:01:30.619867Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"/bin/bash: -c: line 1: syntax error: unexpected end of file\n","output_type":"stream"}]},{"cell_type":"code","source":"wandb login","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **IMPORTING THE NECESSARY LIBRARIES**","metadata":{}},{"cell_type":"code","source":"import os\nimport evaluate\nimport numpy as np\nimport pandas as pd\nfrom datasets import load_dataset, Dataset, DatasetDict\nfrom transformers import AutoTokenizer, Seq2SeqTrainingArguments, Seq2SeqTrainer,DataCollatorForSeq2Seq, AutoModelForSeq2SeqLM","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:30:23.027715Z","iopub.execute_input":"2024-04-12T22:30:23.028049Z","iopub.status.idle":"2024-04-12T22:30:54.855527Z","shell.execute_reply.started":"2024-04-12T22:30:23.028016Z","shell.execute_reply":"2024-04-12T22:30:54.854626Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"2024-04-12 22:30:38.571636: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-12 22:30:38.571761: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-12 22:30:38.842279: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Initialising wandb","metadata":{}},{"cell_type":"code","source":"import wandb","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:30:54.856726Z","iopub.execute_input":"2024-04-12T22:30:54.857377Z","iopub.status.idle":"2024-04-12T22:30:55.819703Z","shell.execute_reply.started":"2024-04-12T22:30:54.857327Z","shell.execute_reply":"2024-04-12T22:30:55.818587Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# **PIPELINE**","metadata":{}},{"cell_type":"code","source":"dataset = load_dataset(\"wmt14\", 'de-en')","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:30:55.820996Z","iopub.execute_input":"2024-04-12T22:30:55.821328Z","iopub.status.idle":"2024-04-12T22:31:17.766582Z","shell.execute_reply.started":"2024-04-12T22:30:55.821298Z","shell.execute_reply":"2024-04-12T22:31:17.765683Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/10.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0fd68d68d7da45d18d8c0e0b04633be0"}},"metadata":{}},{"name":"stderr","text":"Downloading data: 100%|██████████| 280M/280M [00:01<00:00, 167MB/s]  \nDownloading data: 100%|██████████| 265M/265M [00:01<00:00, 175MB/s]  \nDownloading data: 100%|██████████| 273M/273M [00:01<00:00, 182MB/s]  \nDownloading data: 100%|██████████| 474k/474k [00:00<00:00, 2.36MB/s]\nDownloading data: 100%|██████████| 509k/509k [00:00<00:00, 2.86MB/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/4508785 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3423241426104854a571644bf08f7912"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/3000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6422872a5c94a59a1a877341ad7d3cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/3003 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90063295ef4f47a7aeaa34a05040c5a9"}},"metadata":{}}]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:31:17.767796Z","iopub.execute_input":"2024-04-12T22:31:17.768123Z","iopub.status.idle":"2024-04-12T22:31:17.775607Z","shell.execute_reply.started":"2024-04-12T22:31:17.768094Z","shell.execute_reply":"2024-04-12T22:31:17.774553Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['translation'],\n        num_rows: 4508785\n    })\n    validation: Dataset({\n        features: ['translation'],\n        num_rows: 3000\n    })\n    test: Dataset({\n        features: ['translation'],\n        num_rows: 3003\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"new_dataset = dataset[\"train\"].select(range(150000))","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:31:17.776920Z","iopub.execute_input":"2024-04-12T22:31:17.777267Z","iopub.status.idle":"2024-04-12T22:31:17.861551Z","shell.execute_reply.started":"2024-04-12T22:31:17.777238Z","shell.execute_reply":"2024-04-12T22:31:17.860620Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"new_dataset","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:31:17.862883Z","iopub.execute_input":"2024-04-12T22:31:17.863265Z","iopub.status.idle":"2024-04-12T22:31:17.871062Z","shell.execute_reply.started":"2024-04-12T22:31:17.863228Z","shell.execute_reply":"2024-04-12T22:31:17.870097Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['translation'],\n    num_rows: 150000\n})"},"metadata":{}}]},{"cell_type":"code","source":"total_samples = 150000\ntrain_samples = int(total_samples * 0.7)\nvalid_samples = int(total_samples * 0.1)\ntest_samples = total_samples - train_samples - valid_samples","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:31:17.872310Z","iopub.execute_input":"2024-04-12T22:31:17.872685Z","iopub.status.idle":"2024-04-12T22:31:17.879751Z","shell.execute_reply.started":"2024-04-12T22:31:17.872657Z","shell.execute_reply":"2024-04-12T22:31:17.878988Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"train_dataset = new_dataset.select(range(train_samples))\nvalid_dataset = new_dataset.select(range(train_samples, train_samples + valid_samples))\ntest_dataset = new_dataset.select(range(train_samples + valid_samples, total_samples))","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:31:17.880941Z","iopub.execute_input":"2024-04-12T22:31:17.881271Z","iopub.status.idle":"2024-04-12T22:31:17.898650Z","shell.execute_reply.started":"2024-04-12T22:31:17.881198Z","shell.execute_reply":"2024-04-12T22:31:17.897644Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"train_dataset.to_csv(\"/kaggle/working/train_dataset.csv\", index=False)\n\nvalid_dataset.to_csv(\"/kaggle/working/valid_dataset.csv\", index=False)\n\ntest_dataset.to_csv(\"/kaggle/working/test_dataset.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:31:17.899953Z","iopub.execute_input":"2024-04-12T22:31:17.900342Z","iopub.status.idle":"2024-04-12T22:31:21.533452Z","shell.execute_reply.started":"2024-04-12T22:31:17.900292Z","shell.execute_reply":"2024-04-12T22:31:21.532407Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"Creating CSV from Arrow format:   0%|          | 0/105 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8001db3a8a0448738d43261086aa6fc5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Creating CSV from Arrow format:   0%|          | 0/15 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5eee947115e44518b6b9e8c16f3e442"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Creating CSV from Arrow format:   0%|          | 0/30 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a74541795d94486bb0b259b35bac9adb"}},"metadata":{}},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"10158133"},"metadata":{}}]},{"cell_type":"code","source":"df_1 = pd.read_csv(\"/kaggle/working/train_dataset.csv\")\ndf_2 = pd.read_csv(\"/kaggle/working/valid_dataset.csv\")\ndf_3 = pd.read_csv(\"/kaggle/working/test_dataset.csv\")\n\ndf_1['en_length'] = df_1['translation'].apply(lambda x: len(eval(x)['en']))\ndf_2['en_length'] = df_2['translation'].apply(lambda x: len(eval(x)['en']))\ndf_3['en_length'] = df_3['translation'].apply(lambda x: len(eval(x)['en']))\n\ndf_sorted_1 = df_1.sort_values(by='en_length')\ndf_sorted_2 = df_2.sort_values(by='en_length')\ndf_sorted_3 = df_3.sort_values(by='en_length')\n\ndf_sorted_1.drop(columns='en_length', inplace=True)\ndf_sorted_2.drop(columns='en_length', inplace=True)\ndf_sorted_3.drop(columns='en_length', inplace=True)\n\ndf_sorted_1.to_csv(\"/kaggle/working/en_to_de_train_dataset.csv\", index=False)\ndf_sorted_2.to_csv(\"/kaggle/working/en_to_de_valid_dataset.csv\", index=False)\ndf_sorted_3.to_csv(\"/kaggle/working/en_to_de_test_dataset.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T15:56:09.558021Z","iopub.execute_input":"2024-04-12T15:56:09.558316Z","iopub.status.idle":"2024-04-12T15:56:14.988476Z","shell.execute_reply.started":"2024-04-12T15:56:09.558290Z","shell.execute_reply":"2024-04-12T15:56:14.987488Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/working/en_to_de_train_dataset.csv\")\nvalid_df = pd.read_csv(\"/kaggle/working/en_to_de_valid_dataset.csv\")\ntest_df = pd.read_csv(\"/kaggle/working/en_to_de_test_dataset.csv\")\n\ntrain_dataset = Dataset.from_pandas(train_df)\nvalid_dataset = Dataset.from_pandas(valid_df)\ntest_dataset = Dataset.from_pandas(test_df)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T15:56:14.990021Z","iopub.execute_input":"2024-04-12T15:56:14.990693Z","iopub.status.idle":"2024-04-12T15:56:16.189217Z","shell.execute_reply.started":"2024-04-12T15:56:14.990656Z","shell.execute_reply":"2024-04-12T15:56:16.188150Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"checkpoint = \"google-t5/t5-base\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:31:21.534781Z","iopub.execute_input":"2024-04-12T22:31:21.535096Z","iopub.status.idle":"2024-04-12T22:31:22.851032Z","shell.execute_reply.started":"2024-04-12T22:31:21.535067Z","shell.execute_reply":"2024-04-12T22:31:22.849720Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6217cc08c0343aa9eaf8d36c4b1b057"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be90e60ad54746f88e9685dee9be720b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02359851b03d4294964bf98ddfd52e01"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5_fast.py:171: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\nFor now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n- Be aware that you SHOULD NOT rely on google-t5/t5-base automatically truncating your input to 512 when padding/encoding.\n- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **English to German Translation**","metadata":{}},{"cell_type":"code","source":"train_dataset[150]","metadata":{"execution":{"iopub.status.busy":"2024-04-12T15:56:17.072911Z","iopub.execute_input":"2024-04-12T15:56:17.073208Z","iopub.status.idle":"2024-04-12T15:56:18.140585Z","shell.execute_reply.started":"2024-04-12T15:56:17.073182Z","shell.execute_reply":"2024-04-12T15:56:18.138438Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"{'translation': \"{'de': 'Abstimmungen', 'en': 'Vote'}\"}"},"metadata":{}}]},{"cell_type":"code","source":"source_lang = \"en\"\ntarget_lang = \"de\"\nprefix = \"translate English to German: \"\n\ndef preprocess_function(example):\n    if isinstance(example[\"translation\"], str):\n        example[\"translation\"] = eval(example[\"translation\"])\n    \n    input_text = example[\"translation\"][source_lang]\n    target_text = example[\"translation\"][target_lang]\n    \n    # Tokenize input and target text with max_length=128\n    inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n    targets = tokenizer(target_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n    \n    # Prepare model inputs and labels\n    model_inputs = {\n        \"input_ids\": inputs.input_ids.flatten(),\n        \"attention_mask\": inputs.attention_mask.flatten(),\n        \"labels\": targets.input_ids.flatten()\n    }\n    \n    return model_inputs","metadata":{"execution":{"iopub.status.busy":"2024-04-12T15:56:18.141920Z","iopub.execute_input":"2024-04-12T15:56:18.142300Z","iopub.status.idle":"2024-04-12T15:56:18.246883Z","shell.execute_reply.started":"2024-04-12T15:56:18.142259Z","shell.execute_reply":"2024-04-12T15:56:18.245743Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"tokenized_train_example = preprocess_function(train_dataset[150])\n\ntokenized_valid_example = preprocess_function(valid_dataset[150])\n\ntokenized_test_example = preprocess_function(test_dataset[150])","metadata":{"execution":{"iopub.status.busy":"2024-04-12T15:56:18.248338Z","iopub.execute_input":"2024-04-12T15:56:18.248723Z","iopub.status.idle":"2024-04-12T15:56:18.414597Z","shell.execute_reply.started":"2024-04-12T15:56:18.248688Z","shell.execute_reply":"2024-04-12T15:56:18.413449Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"tokenized_train = [preprocess_function(example) for example in train_dataset]\ntokenized_valid = [preprocess_function(example) for example in valid_dataset]\ntokenized_test = [preprocess_function(example) for example in test_dataset]","metadata":{"execution":{"iopub.status.busy":"2024-04-12T15:56:18.415774Z","iopub.execute_input":"2024-04-12T15:56:18.416056Z","iopub.status.idle":"2024-04-12T15:58:18.066271Z","shell.execute_reply.started":"2024-04-12T15:56:18.416032Z","shell.execute_reply":"2024-04-12T15:58:18.065427Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"tokenized_train_example","metadata":{"execution":{"iopub.status.busy":"2024-04-12T15:58:18.072271Z","iopub.execute_input":"2024-04-12T15:58:18.073042Z","iopub.status.idle":"2024-04-12T15:58:18.102498Z","shell.execute_reply.started":"2024-04-12T15:58:18.072999Z","shell.execute_reply":"2024-04-12T15:58:18.101475Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"{'input_ids': tensor([3152,   17,   15,    1]),\n 'attention_mask': tensor([1, 1, 1, 1]),\n 'labels': tensor([  891, 11822,    35,     1])}"},"metadata":{}}]},{"cell_type":"code","source":"data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T15:58:18.103690Z","iopub.execute_input":"2024-04-12T15:58:18.103998Z","iopub.status.idle":"2024-04-12T15:58:18.108541Z","shell.execute_reply.started":"2024-04-12T15:58:18.103972Z","shell.execute_reply":"2024-04-12T15:58:18.107487Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"metric = evaluate.load(\"sacrebleu\")","metadata":{"execution":{"iopub.status.busy":"2024-04-12T15:58:18.109807Z","iopub.execute_input":"2024-04-12T15:58:18.110175Z","iopub.status.idle":"2024-04-12T15:58:18.742327Z","shell.execute_reply.started":"2024-04-12T15:58:18.110139Z","shell.execute_reply":"2024-04-12T15:58:18.741347Z"},"trusted":true},"execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/8.15k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a598d522cc80450a910eda336f47dd24"}},"metadata":{}}]},{"cell_type":"code","source":"def postprocess_text(preds, labels):\n    preds = [pred.strip() for pred in preds]\n    labels = [[label.strip()] for label in labels]\n\n    return preds, labels\n\n\ndef compute_metrics(eval_preds):\n    preds, labels = eval_preds\n    if isinstance(preds, tuple):\n        preds = preds[0]\n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n\n    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n    result = {\"bleu\": result[\"score\"]}\n\n    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n    result[\"gen_len\"] = np.mean(prediction_lens)\n    result = {k: round(v, 4) for k, v in result.items()}\n    return result","metadata":{"execution":{"iopub.status.busy":"2024-04-12T15:58:18.743669Z","iopub.execute_input":"2024-04-12T15:58:18.744286Z","iopub.status.idle":"2024-04-12T15:58:18.752906Z","shell.execute_reply.started":"2024-04-12T15:58:18.744259Z","shell.execute_reply":"2024-04-12T15:58:18.751930Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T15:58:18.754018Z","iopub.execute_input":"2024-04-12T15:58:18.754311Z","iopub.status.idle":"2024-04-12T15:58:24.126405Z","shell.execute_reply.started":"2024-04-12T15:58:18.754286Z","shell.execute_reply":"2024-04-12T15:58:24.125538Z"},"trusted":true},"execution_count":32,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80bbd25dd42e40e0bc17e4b367c8799b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"521ab80862c848fc9d1e8ea0b0f337bd"}},"metadata":{}}]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2024-04-12T15:58:24.127833Z","iopub.execute_input":"2024-04-12T15:58:24.128192Z","iopub.status.idle":"2024-04-12T15:58:24.138688Z","shell.execute_reply.started":"2024-04-12T15:58:24.128158Z","shell.execute_reply":"2024-04-12T15:58:24.137816Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"T5ForConditionalGeneration(\n  (shared): Embedding(32128, 768)\n  (encoder): T5Stack(\n    (embed_tokens): Embedding(32128, 768)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n              (relative_attention_bias): Embedding(32, 12)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-11): 11 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (decoder): T5Stack(\n    (embed_tokens): Embedding(32128, 768)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n              (relative_attention_bias): Embedding(32, 12)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-11): 11 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    output_dir = \"./model\",\n    evaluation_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    weight_decay=0.01,\n    num_train_epochs=1,\n    report_to=\"wandb\",\n    predict_with_generate=True,\n    fp16=True,\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T15:58:24.140091Z","iopub.execute_input":"2024-04-12T15:58:24.140947Z","iopub.status.idle":"2024-04-12T15:58:24.255703Z","shell.execute_reply.started":"2024-04-12T15:58:24.140914Z","shell.execute_reply":"2024-04-12T15:58:24.254690Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"trainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train,\n    eval_dataset=tokenized_valid,\n    tokenizer=tokenizer,\n    data_collator = data_collator,\n    compute_metrics=compute_metrics,\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T15:58:24.256890Z","iopub.execute_input":"2024-04-12T15:58:24.257208Z","iopub.status.idle":"2024-04-12T15:58:24.710470Z","shell.execute_reply.started":"2024-04-12T15:58:24.257182Z","shell.execute_reply":"2024-04-12T15:58:24.709487Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-04-12T15:58:24.711748Z","iopub.execute_input":"2024-04-12T15:58:24.712097Z","iopub.status.idle":"2024-04-12T16:59:10.171828Z","shell.execute_reply.started":"2024-04-12T15:58:24.712063Z","shell.execute_reply":"2024-04-12T16:59:10.171031Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.5"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240412_155831-ta6u8pyo</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/naik-9/huggingface/runs/ta6u8pyo/workspace' target=\"_blank\">dry-firebrand-4</a></strong> to <a href='https://wandb.ai/naik-9/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/naik-9/huggingface' target=\"_blank\">https://wandb.ai/naik-9/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/naik-9/huggingface/runs/ta6u8pyo/workspace' target=\"_blank\">https://wandb.ai/naik-9/huggingface/runs/ta6u8pyo/workspace</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3282' max='3282' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3282/3282 1:00:16, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Bleu</th>\n      <th>Gen Len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.081100</td>\n      <td>0.932104</td>\n      <td>8.340600</td>\n      <td>18.002200</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=3282, training_loss=1.1024056015619048, metrics={'train_runtime': 3644.8688, 'train_samples_per_second': 28.808, 'train_steps_per_second': 0.9, 'total_flos': 1.081040125759488e+16, 'train_loss': 1.1024056015619048, 'epoch': 1.0})"},"metadata":{}}]},{"cell_type":"code","source":"wandb.finish()","metadata":{"execution":{"iopub.status.busy":"2024-04-12T16:59:15.607347Z","iopub.execute_input":"2024-04-12T16:59:15.607760Z","iopub.status.idle":"2024-04-12T16:59:18.694226Z","shell.execute_reply.started":"2024-04-12T16:59:15.607715Z","shell.execute_reply":"2024-04-12T16:59:18.693252Z"},"trusted":true},"execution_count":37,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.030 MB of 0.030 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>▁</td></tr><tr><td>eval/gen_len</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▂▄▅▆▇██</td></tr><tr><td>train/global_step</td><td>▁▂▄▅▆▇██</td></tr><tr><td>train/grad_norm</td><td>▁█▄▅▄▇</td></tr><tr><td>train/learning_rate</td><td>█▇▅▄▂▁</td></tr><tr><td>train/loss</td><td>█▃▂▂▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>8.3406</td></tr><tr><td>eval/gen_len</td><td>18.0022</td></tr><tr><td>eval/loss</td><td>0.9321</td></tr><tr><td>eval/runtime</td><td>325.2375</td></tr><tr><td>eval/samples_per_second</td><td>46.12</td></tr><tr><td>eval/steps_per_second</td><td>1.442</td></tr><tr><td>total_flos</td><td>1.081040125759488e+16</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>3282</td></tr><tr><td>train/grad_norm</td><td>61717.3125</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.0811</td></tr><tr><td>train_loss</td><td>1.10241</td></tr><tr><td>train_runtime</td><td>3644.8688</td></tr><tr><td>train_samples_per_second</td><td>28.808</td></tr><tr><td>train_steps_per_second</td><td>0.9</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">dry-firebrand-4</strong> at: <a href='https://wandb.ai/naik-9/huggingface/runs/ta6u8pyo/workspace' target=\"_blank\">https://wandb.ai/naik-9/huggingface/runs/ta6u8pyo/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240412_155831-ta6u8pyo/logs</code>"},"metadata":{}}]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-04-12T17:07:16.153915Z","iopub.execute_input":"2024-04-12T17:07:16.155163Z","iopub.status.idle":"2024-04-12T17:07:16.179031Z","shell.execute_reply.started":"2024-04-12T17:07:16.155115Z","shell.execute_reply":"2024-04-12T17:07:16.178024Z"},"trusted":true},"execution_count":48,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25614b7ff10246faa5c2ad717172fda1"}},"metadata":{}}]},{"cell_type":"code","source":"trainer.push_to_hub(\"Reyansh4/NMT_T5_wmt14_en_to_de\")","metadata":{"execution":{"iopub.status.busy":"2024-04-12T17:07:28.826518Z","iopub.execute_input":"2024-04-12T17:07:28.827356Z","iopub.status.idle":"2024-04-12T17:07:54.854032Z","shell.execute_reply.started":"2024-04-12T17:07:28.827327Z","shell.execute_reply":"2024-04-12T17:07:54.852977Z"},"trusted":true},"execution_count":49,"outputs":[{"output_type":"display_data","data":{"text/plain":"Upload 3 LFS files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b84aa3504c04afda144255a1d1907f2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad5611b90d034c05a6a010a6729aa079"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"daf613dfd47243adaaa248891cd5d960"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"training_args.bin:   0%|          | 0.00/5.05k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07c693efca994d95b6eaf53fb5f42a9a"}},"metadata":{}},{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/Reyansh4/model/commit/ee5a16cb5758cfc81e71710577259ee5bb2ebf3d', commit_message='Reyansh4/NMT_T5_wmt14_en_to_de', commit_description='', oid='ee5a16cb5758cfc81e71710577259ee5bb2ebf3d', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.push_to_hub(\"Reyansh4/NMT_T5_wmt14_en_to_de\")","metadata":{"execution":{"iopub.status.busy":"2024-04-12T17:07:54.855741Z","iopub.execute_input":"2024-04-12T17:07:54.856044Z","iopub.status.idle":"2024-04-12T17:07:59.604388Z","shell.execute_reply.started":"2024-04-12T17:07:54.856017Z","shell.execute_reply":"2024-04-12T17:07:59.603378Z"},"trusted":true},"execution_count":50,"outputs":[{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ec68a0f0938401891d45e25aa26ffd6"}},"metadata":{}},{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/Reyansh4/NMT_T5_wmt14_en_to_de/commit/c6dfbace323c4444c1d9ad2b25eff779b6b159fb', commit_message='Upload tokenizer', commit_description='', oid='c6dfbace323c4444c1d9ad2b25eff779b6b159fb', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\n# Load the tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"/kaggle/working/model/checkpoint-3000\")\n\n# Load the model\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"/kaggle/working/model/checkpoint-3000\")\n\ninput_text = \"this is something very good\"\n\ninputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True)\noutputs = model.generate(input_ids=inputs.input_ids, attention_mask=inputs.attention_mask)\ntranslated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint(\"Translated Text:\", translated_text)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T17:30:41.835756Z","iopub.execute_input":"2024-04-12T17:30:41.836523Z","iopub.status.idle":"2024-04-12T17:30:43.316683Z","shell.execute_reply.started":"2024-04-12T17:30:41.836478Z","shell.execute_reply":"2024-04-12T17:30:43.315548Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Translated Text: Das ist etwas sehr Gutes.\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"/kaggle/working/model/checkpoint-3000\")\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"/kaggle/working/model/checkpoint-3000\")","metadata":{"execution":{"iopub.status.busy":"2024-04-12T17:31:30.877831Z","iopub.execute_input":"2024-04-12T17:31:30.878480Z","iopub.status.idle":"2024-04-12T17:31:31.804586Z","shell.execute_reply.started":"2024-04-12T17:31:30.878446Z","shell.execute_reply":"2024-04-12T17:31:31.803558Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"import gradio as gr\n\ngr.Interface(\n    fn=translate,\n    inputs=gr.Textbox(lines=5, label=\"Input Text\"),\n    outputs=\"Translated Query\",\n    title=\"Translation from English to German\",\n).launch(share=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **German to English Translation**","metadata":{}},{"cell_type":"code","source":"df_1 = pd.read_csv(\"/kaggle/working/train_dataset.csv\")\ndf_2 = pd.read_csv(\"/kaggle/working/valid_dataset.csv\")\ndf_3 = pd.read_csv(\"/kaggle/working/test_dataset.csv\")\n\ndf_1['de_length'] = df_1['translation'].apply(lambda x: len(eval(x)['de']))\ndf_2['de_length'] = df_2['translation'].apply(lambda x: len(eval(x)['de']))\ndf_3['de_length'] = df_3['translation'].apply(lambda x: len(eval(x)['de']))\n\ndf_sorted_1 = df_1.sort_values(by='de_length')\ndf_sorted_2 = df_2.sort_values(by='de_length')\ndf_sorted_3 = df_3.sort_values(by='de_length')\n\ndf_sorted_1.drop(columns='de_length', inplace=True)\ndf_sorted_2.drop(columns='de_length', inplace=True)\ndf_sorted_3.drop(columns='de_length', inplace=True)\n\ndf_sorted_1.to_csv(\"/kaggle/working/de_to_en_train_dataset.csv\", index=False)\ndf_sorted_2.to_csv(\"/kaggle/working/de_to_en_valid_dataset.csv\", index=False)\ndf_sorted_3.to_csv(\"/kaggle/working/de_to_en_test_dataset.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:31:22.852801Z","iopub.execute_input":"2024-04-12T22:31:22.853150Z","iopub.status.idle":"2024-04-12T22:31:28.978688Z","shell.execute_reply.started":"2024-04-12T22:31:22.853121Z","shell.execute_reply":"2024-04-12T22:31:28.977765Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/working/de_to_en_train_dataset.csv\")\nvalid_df = pd.read_csv(\"/kaggle/working/de_to_en_valid_dataset.csv\")\ntest_df = pd.read_csv(\"/kaggle/working/de_to_en_test_dataset.csv\")\n\ntrain_dataset = Dataset.from_pandas(train_df)\nvalid_dataset = Dataset.from_pandas(valid_df)\ntest_dataset = Dataset.from_pandas(test_df)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:31:28.979946Z","iopub.execute_input":"2024-04-12T22:31:28.980296Z","iopub.status.idle":"2024-04-12T22:31:30.169205Z","shell.execute_reply.started":"2024-04-12T22:31:28.980266Z","shell.execute_reply":"2024-04-12T22:31:30.168300Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"train_dataset[150]","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:31:30.170595Z","iopub.execute_input":"2024-04-12T22:31:30.170985Z","iopub.status.idle":"2024-04-12T22:31:31.044572Z","shell.execute_reply.started":"2024-04-12T22:31:30.170942Z","shell.execute_reply":"2024-04-12T22:31:31.043286Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"{'translation': \"{'de': 'Weshalb?', 'en': 'Why?'}\"}"},"metadata":{}}]},{"cell_type":"code","source":"source_lang = \"de\"\ntarget_lang = \"en\"\nprefix = \"translate German to English: \"\n\ndef preprocess_function(example):\n    if isinstance(example[\"translation\"], str):\n        example[\"translation\"] = eval(example[\"translation\"])\n    \n    input_text = example[\"translation\"][source_lang]\n    target_text = example[\"translation\"][target_lang]\n    \n    # Tokenize input and target text with max_length=128\n    inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n    targets = tokenizer(target_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n    \n    # Prepare model inputs and labels\n    model_inputs = {\n        \"input_ids\": inputs.input_ids.flatten(),\n        \"attention_mask\": inputs.attention_mask.flatten(),\n        \"labels\": targets.input_ids.flatten()\n    }\n    \n    return model_inputs","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:31:31.046002Z","iopub.execute_input":"2024-04-12T22:31:31.046439Z","iopub.status.idle":"2024-04-12T22:31:31.056255Z","shell.execute_reply.started":"2024-04-12T22:31:31.046400Z","shell.execute_reply":"2024-04-12T22:31:31.054892Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"tokenized_train_example = preprocess_function(train_dataset[150])\n\ntokenized_valid_example = preprocess_function(valid_dataset[150])\n\ntokenized_test_example = preprocess_function(test_dataset[150])","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:31:31.057988Z","iopub.execute_input":"2024-04-12T22:31:31.058340Z","iopub.status.idle":"2024-04-12T22:31:31.116822Z","shell.execute_reply.started":"2024-04-12T22:31:31.058310Z","shell.execute_reply":"2024-04-12T22:31:31.115869Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"tokenized_train = [preprocess_function(example) for example in train_dataset]\ntokenized_valid = [preprocess_function(example) for example in valid_dataset]\ntokenized_test = [preprocess_function(example) for example in test_dataset]","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:31:31.118418Z","iopub.execute_input":"2024-04-12T22:31:31.118848Z","iopub.status.idle":"2024-04-12T22:33:45.242819Z","shell.execute_reply.started":"2024-04-12T22:31:31.118814Z","shell.execute_reply":"2024-04-12T22:33:45.241884Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"tokenized_train_example","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:33:45.244058Z","iopub.execute_input":"2024-04-12T22:33:45.244389Z","iopub.status.idle":"2024-04-12T22:33:45.277723Z","shell.execute_reply.started":"2024-04-12T22:33:45.244358Z","shell.execute_reply":"2024-04-12T22:33:45.276685Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"{'input_ids': tensor([  101, 14737,    58,     1]),\n 'attention_mask': tensor([1, 1, 1, 1]),\n 'labels': tensor([1615,   58,    1])}"},"metadata":{}}]},{"cell_type":"code","source":"data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:33:45.279020Z","iopub.execute_input":"2024-04-12T22:33:45.279440Z","iopub.status.idle":"2024-04-12T22:33:45.284535Z","shell.execute_reply.started":"2024-04-12T22:33:45.279401Z","shell.execute_reply":"2024-04-12T22:33:45.283521Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"metric = evaluate.load(\"sacrebleu\")","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:33:45.290665Z","iopub.execute_input":"2024-04-12T22:33:45.291066Z","iopub.status.idle":"2024-04-12T22:33:45.958758Z","shell.execute_reply.started":"2024-04-12T22:33:45.291037Z","shell.execute_reply":"2024-04-12T22:33:45.957652Z"},"trusted":true},"execution_count":31,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/8.15k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e648d7282eb4b08924249e068721352"}},"metadata":{}}]},{"cell_type":"code","source":"def postprocess_text(preds, labels):\n    preds = [pred.strip() for pred in preds]\n    labels = [[label.strip()] for label in labels]\n\n    return preds, labels\n\n\ndef compute_metrics(eval_preds):\n    preds, labels = eval_preds\n    if isinstance(preds, tuple):\n        preds = preds[0]\n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n\n    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n    result = {\"bleu\": result[\"score\"]}\n\n    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n    result[\"gen_len\"] = np.mean(prediction_lens)\n    result = {k: round(v, 4) for k, v in result.items()}\n    return result","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:33:45.961189Z","iopub.execute_input":"2024-04-12T22:33:45.962557Z","iopub.status.idle":"2024-04-12T22:33:45.971486Z","shell.execute_reply.started":"2024-04-12T22:33:45.962524Z","shell.execute_reply":"2024-04-12T22:33:45.970508Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:33:45.972748Z","iopub.execute_input":"2024-04-12T22:33:45.973109Z","iopub.status.idle":"2024-04-12T22:33:51.574992Z","shell.execute_reply.started":"2024-04-12T22:33:45.973075Z","shell.execute_reply":"2024-04-12T22:33:51.574168Z"},"trusted":true},"execution_count":33,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"228e967120ee44cfa78685791fcf5c81"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54612fe6b3d84aa1a4717537285ab35b"}},"metadata":{}}]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:33:51.576156Z","iopub.execute_input":"2024-04-12T22:33:51.576477Z","iopub.status.idle":"2024-04-12T22:33:51.587048Z","shell.execute_reply.started":"2024-04-12T22:33:51.576444Z","shell.execute_reply":"2024-04-12T22:33:51.586202Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"T5ForConditionalGeneration(\n  (shared): Embedding(32128, 768)\n  (encoder): T5Stack(\n    (embed_tokens): Embedding(32128, 768)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n              (relative_attention_bias): Embedding(32, 12)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-11): 11 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (decoder): T5Stack(\n    (embed_tokens): Embedding(32128, 768)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n              (relative_attention_bias): Embedding(32, 12)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-11): 11 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    output_dir = \"./model\",\n    evaluation_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    weight_decay=0.01,\n    num_train_epochs=1,\n    predict_with_generate=True,\n    report_to=\"wandb\",\n    fp16=True,\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:33:51.588430Z","iopub.execute_input":"2024-04-12T22:33:51.588755Z","iopub.status.idle":"2024-04-12T22:33:51.712574Z","shell.execute_reply.started":"2024-04-12T22:33:51.588728Z","shell.execute_reply":"2024-04-12T22:33:51.711685Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"trainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train,\n    eval_dataset=tokenized_valid,\n    tokenizer=tokenizer,\n    data_collator = data_collator,\n    compute_metrics=compute_metrics,\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:33:51.713739Z","iopub.execute_input":"2024-04-12T22:33:51.714041Z","iopub.status.idle":"2024-04-12T22:33:52.190524Z","shell.execute_reply.started":"2024-04-12T22:33:51.714014Z","shell.execute_reply":"2024-04-12T22:33:52.189370Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:33:52.191960Z","iopub.execute_input":"2024-04-12T22:33:52.192408Z","iopub.status.idle":"2024-04-12T23:33:05.895983Z","shell.execute_reply.started":"2024-04-12T22:33:52.192369Z","shell.execute_reply":"2024-04-12T23:33:05.894690Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.5"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240412_223405-grc5dt0n</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/naik-9/huggingface/runs/grc5dt0n/workspace' target=\"_blank\">fancy-haze-6</a></strong> to <a href='https://wandb.ai/naik-9/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/naik-9/huggingface' target=\"_blank\">https://wandb.ai/naik-9/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/naik-9/huggingface/runs/grc5dt0n/workspace' target=\"_blank\">https://wandb.ai/naik-9/huggingface/runs/grc5dt0n/workspace</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3282' max='3282' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3282/3282 58:38, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Bleu</th>\n      <th>Gen Len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.812800</td>\n      <td>1.568120</td>\n      <td>10.498300</td>\n      <td>17.378900</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=3282, training_loss=1.8945422500898603, metrics={'train_runtime': 3553.0277, 'train_samples_per_second': 29.552, 'train_steps_per_second': 0.924, 'total_flos': 1.365896354512896e+16, 'train_loss': 1.8945422500898603, 'epoch': 1.0})"},"metadata":{}}]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-04-12T23:33:22.885102Z","iopub.execute_input":"2024-04-12T23:33:22.885540Z","iopub.status.idle":"2024-04-12T23:33:22.924766Z","shell.execute_reply.started":"2024-04-12T23:33:22.885502Z","shell.execute_reply":"2024-04-12T23:33:22.923394Z"},"trusted":true},"execution_count":45,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2044b3cc646b420caccf8bb845544ca4"}},"metadata":{}}]},{"cell_type":"code","source":"trainer.push_to_hub(\"Reyansh4/NMT_T5_wmt14_de_to_en\")","metadata":{"execution":{"iopub.status.busy":"2024-04-12T23:33:39.771686Z","iopub.execute_input":"2024-04-12T23:33:39.772526Z","iopub.status.idle":"2024-04-12T23:34:07.020300Z","shell.execute_reply.started":"2024-04-12T23:33:39.772490Z","shell.execute_reply":"2024-04-12T23:34:07.019014Z"},"trusted":true},"execution_count":46,"outputs":[{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8cae16a6a63e43669c0d0160f1729886"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ca81276905f4f45a8f10a59df9d0156"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"training_args.bin:   0%|          | 0.00/5.05k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0694ab46b6df4125a3e57ba26d25545c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Upload 3 LFS files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e6c8cea66684a6c8281e97b8ec7fb58"}},"metadata":{}},{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/Reyansh4/model/commit/2d14a58386c1a9568fbdefa8ca20e17d1e0731dc', commit_message='Reyansh4/NMT_T5_wmt14_de_to_en', commit_description='', oid='2d14a58386c1a9568fbdefa8ca20e17d1e0731dc', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.push_to_hub(\"Reyansh4/NMT_T5_wmt14_de_to_en\")","metadata":{"execution":{"iopub.status.busy":"2024-04-12T23:34:09.664908Z","iopub.execute_input":"2024-04-12T23:34:09.665370Z","iopub.status.idle":"2024-04-12T23:34:11.888937Z","shell.execute_reply.started":"2024-04-12T23:34:09.665320Z","shell.execute_reply":"2024-04-12T23:34:11.887658Z"},"trusted":true},"execution_count":47,"outputs":[{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec9fc9c9621942059a26fa9b5825d1fe"}},"metadata":{}},{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/Reyansh4/NMT_T5_wmt14_de_to_en/commit/f95540f9426712416ac8b2eb3ddf6ab91de4c818', commit_message='Upload tokenizer', commit_description='', oid='f95540f9426712416ac8b2eb3ddf6ab91de4c818', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"code","source":"wandb.finish()","metadata":{"execution":{"iopub.status.busy":"2024-04-12T23:34:14.024579Z","iopub.execute_input":"2024-04-12T23:34:14.024983Z","iopub.status.idle":"2024-04-12T23:34:19.294397Z","shell.execute_reply.started":"2024-04-12T23:34:14.024941Z","shell.execute_reply":"2024-04-12T23:34:19.293186Z"},"trusted":true},"execution_count":48,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>▁</td></tr><tr><td>eval/gen_len</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▂▄▅▆▇██</td></tr><tr><td>train/global_step</td><td>▁▂▄▅▆▇██</td></tr><tr><td>train/grad_norm</td><td>█▅▁█▂▂</td></tr><tr><td>train/learning_rate</td><td>█▇▅▄▂▁</td></tr><tr><td>train/loss</td><td>█▄▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>10.4983</td></tr><tr><td>eval/gen_len</td><td>17.3789</td></tr><tr><td>eval/loss</td><td>1.56812</td></tr><tr><td>eval/runtime</td><td>344.3344</td></tr><tr><td>eval/samples_per_second</td><td>43.562</td></tr><tr><td>eval/steps_per_second</td><td>1.362</td></tr><tr><td>total_flos</td><td>1.365896354512896e+16</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>3282</td></tr><tr><td>train/grad_norm</td><td>82960.59375</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.8128</td></tr><tr><td>train_loss</td><td>1.89454</td></tr><tr><td>train_runtime</td><td>3553.0277</td></tr><tr><td>train_samples_per_second</td><td>29.552</td></tr><tr><td>train_steps_per_second</td><td>0.924</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">fancy-haze-6</strong> at: <a href='https://wandb.ai/naik-9/huggingface/runs/grc5dt0n/workspace' target=\"_blank\">https://wandb.ai/naik-9/huggingface/runs/grc5dt0n/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240412_223405-grc5dt0n/logs</code>"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\n# Load the tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"/kaggle/working/model/checkpoint-3000\")\n\n# Load the model\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"/kaggle/working/model/checkpoint-3000\")\n\ninput_text = \"Das ist etwas sehr Gutes\"\n\ninputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True)\noutputs = model.generate(input_ids=inputs.input_ids, attention_mask=inputs.attention_mask)\ntranslated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint(\"Translated Text:\", translated_text)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T23:34:24.358392Z","iopub.execute_input":"2024-04-12T23:34:24.358816Z","iopub.status.idle":"2024-04-12T23:34:25.772112Z","shell.execute_reply.started":"2024-04-12T23:34:24.358782Z","shell.execute_reply":"2024-04-12T23:34:25.770899Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Translated Text: That is something very good.\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"Reyansh4/NMT_T5_wmt14_de_to_en\")\nmodel = AutoModelForSequenceClassification.from_pretrained(\"Reyansh4/NMT_T5_wmt14_de_to_en\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gradio as gr\n\ngr.Interface(\n    fn=translate,\n    inputs=gr.Textbox(lines=5, label=\"Input Text\"),\n    outputs=\"Translated Query\",\n    title=\"Translation from German to English\",\n).launch(share=True)","metadata":{},"execution_count":null,"outputs":[]}]}